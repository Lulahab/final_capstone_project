{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: Abercrombie & Fitch haul\n"
     ]
    },
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?q=Abercrombie+%26+Fitch+haul&type=video&part=id%2Csnippet&maxResults=50&publishedAfter=2020-01-01T00%3A00%3A00Z&publishedBefore=2025-01-01T00%3A00%3A00Z&key=AIzaSyDe_5sxeLJE4Mj0JXQkenQjoi5Kay6367o&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 49\u001b[0m\n\u001b[0;32m     36\u001b[0m page_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     search_response \u001b[38;5;241m=\u001b[39m youtube\u001b[38;5;241m.\u001b[39msearch()\u001b[38;5;241m.\u001b[39mlist(\n\u001b[0;32m     40\u001b[0m         q\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m         part\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid,snippet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m# The maximum number of results in a single response\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;66;03m# must be <= 50 per YouTube API rules.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         maxResults\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     46\u001b[0m         publishedAfter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020-01-01T00:00:00Z\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     47\u001b[0m         publishedBefore\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2025-01-01T00:00:00Z\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     48\u001b[0m         pageToken\u001b[38;5;241m=\u001b[39mpage_token\n\u001b[1;32m---> 49\u001b[0m     )\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Collect video IDs from this page of results\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     items \u001b[38;5;241m=\u001b[39m search_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m     callback(resp)\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?q=Abercrombie+%26+Fitch+haul&type=video&part=id%2Csnippet&maxResults=50&publishedAfter=2020-01-01T00%3A00%3A00Z&publishedBefore=2025-01-01T00%3A00%3A00Z&key=AIzaSyDe_5sxeLJE4Mj0JXQkenQjoi5Kay6367o&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# 1. SETUP: API Key and YouTube client\n",
    "API_KEY = os.getenv(\"you_tube_api\")  # Ensure environment variable is set\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"YouTube API key not found. Please set the 'you_tube_api' environment variable.\")\n",
    "\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "# 2. SEARCH QUERIES\n",
    "search_queries = [\n",
    "    \"Abercrombie & Fitch haul\",\n",
    "    \"Abercrombie try-on\",\n",
    "    \"Abercrombie jeans review\",\n",
    "    \"curve love\",\n",
    "    \"abercrombie\",\n",
    "    \"Abercrombie\",\n",
    "    \"Abercrombie fall fashion\",\n",
    "    \"Abercrombie winter outfits\",\n",
    "    \"Abercrombie shopping haul\"\n",
    "]\n",
    "\n",
    "# 3. KEYWORDS TO EXCLUDE\n",
    "exclude_keywords = [\"ceo\", \"scandal\", \"charged\", \"arrested\", \"indicted\", \"trafficking\", \"lawsuit\"]\n",
    "\n",
    "# ------------------------------------------------\n",
    "# STEP A: Perform YouTube Searches with Pagination\n",
    "# ------------------------------------------------\n",
    "\n",
    "all_video_ids = set()  # Use a set to avoid duplicates across queries\n",
    "\n",
    "for query in search_queries:\n",
    "    print(f\"Searching for: {query}\")\n",
    "    page_token = None\n",
    "\n",
    "    while True:\n",
    "        search_response = youtube.search().list(\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            part=\"id,snippet\",\n",
    "            # The maximum number of results in a single response\n",
    "            # must be <= 50 per YouTube API rules.\n",
    "            maxResults=50,\n",
    "            publishedAfter='2020-01-01T00:00:00Z',\n",
    "            publishedBefore='2025-01-01T00:00:00Z',\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "\n",
    "        # Collect video IDs from this page of results\n",
    "        items = search_response.get(\"items\", [])\n",
    "        for item in items:\n",
    "            video_id = item[\"id\"][\"videoId\"]\n",
    "            all_video_ids.add(video_id)\n",
    "\n",
    "        # Check if there's another page\n",
    "        page_token = search_response.get(\"nextPageToken\")\n",
    "        if not page_token:\n",
    "            break\n",
    "\n",
    "print(f\"\\nFound a total of {len(all_video_ids)} unique video IDs from all queries.\\n\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# STEP B: Fetch Video Statistics in Batches of 50\n",
    "# ------------------------------------------------\n",
    "\n",
    "all_video_details = []\n",
    "\n",
    "# Convert set to list for easier slicing\n",
    "all_video_ids_list = list(all_video_ids)\n",
    "\n",
    "for i in range(0, len(all_video_ids_list), 50):\n",
    "    # Get a slice of up to 50 IDs\n",
    "    subset_ids = all_video_ids_list[i : i + 50]\n",
    "\n",
    "    # Request stats for this batch\n",
    "    video_stats_response = youtube.videos().list(\n",
    "        part=\"snippet,statistics\",\n",
    "        id=\",\".join(subset_ids)\n",
    "    ).execute()\n",
    "\n",
    "    # Add the items from this response to our master list\n",
    "    all_video_details.extend(video_stats_response.get(\"items\", []))\n",
    "\n",
    "print(f\"Retrieved statistics for {len(all_video_details)} videos.\\n\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# STEP C: Filter Out Videos with Excluded Keywords\n",
    "# ------------------------------------------------\n",
    "\n",
    "filtered_video_data = []\n",
    "\n",
    "for video in all_video_details:\n",
    "    snippet = video.get(\"snippet\", {})\n",
    "    stats = video.get(\"statistics\", {})\n",
    "\n",
    "    title = snippet.get(\"title\", \"\")\n",
    "    title_lower = title.lower()\n",
    "\n",
    "    # Check if any excluded keyword is in the title\n",
    "    if not any(excluded in title_lower for excluded in exclude_keywords):\n",
    "        filtered_video_data.append({\n",
    "            \"Title\": title,\n",
    "            \"Views\": int(stats.get(\"viewCount\", 0)),\n",
    "            \"Likes\": int(stats.get(\"likeCount\", 0)),\n",
    "            \"Comments\": int(stats.get(\"commentCount\", 0)),\n",
    "            \"Published Date\": snippet.get(\"publishedAt\"),\n",
    "            \"Video ID\": video.get(\"id\")\n",
    "        })\n",
    "\n",
    "print(f\"Number of filtered videos (without excluded keywords): {len(filtered_video_data)}\\n\")\n",
    "\n",
    "# OPTIONAL: Print some sample data\n",
    "for vid in filtered_video_data[:5]:\n",
    "    print(vid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Views  Likes  Comments  \\\n",
      "0  SUMMER TRY-ON HAUL | ABERCROMBIE, MASSIMO DUTT...  27156    647        29   \n",
      "1  Casual Winter Outfits ❄ | Amazon Corset | Get ...   7579    240         4   \n",
      "2  Abercrombie Haul. Shop on description😉 #abercr...   6139     58         0   \n",
      "3  Best effort to save a goal.. #efootball #pes20...   1394     30         0   \n",
      "4       Abercrombie fall sweater vest 😍 #abercrombie    609      6         2   \n",
      "\n",
      "         Published Date     Video ID  \n",
      "0  2024-06-07T16:49:41Z  mJtVWvBLltg  \n",
      "1  2023-01-31T16:52:14Z  4DfMiBEZm6Q  \n",
      "2  2022-08-31T14:55:56Z  f9ZbRX1ZeGk  \n",
      "3  2023-04-10T07:08:44Z  vdF7WLM7q4w  \n",
      "4  2024-09-13T17:18:36Z  -kQoE1P4fnE  \n",
      "Saved DataFrame to 'my_youtube_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(filtered_video_data)\n",
    "\n",
    "# Now you have a pandas DataFrame; you can print, analyze, etc.\n",
    "print(df.head())\n",
    "\n",
    "# Save to CSV w\n",
    "df.to_csv(\"my_youtube_data.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved DataFrame to 'my_youtube_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Video ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUMMER TRY-ON HAUL | ABERCROMBIE, MASSIMO DUTT...</td>\n",
       "      <td>27156</td>\n",
       "      <td>647</td>\n",
       "      <td>29</td>\n",
       "      <td>2024-06-07T16:49:41Z</td>\n",
       "      <td>mJtVWvBLltg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casual Winter Outfits ❄ | Amazon Corset | Get ...</td>\n",
       "      <td>7579</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-31T16:52:14Z</td>\n",
       "      <td>4DfMiBEZm6Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abercrombie Haul. Shop on description😉 #abercr...</td>\n",
       "      <td>6139</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-31T14:55:56Z</td>\n",
       "      <td>f9ZbRX1ZeGk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best effort to save a goal.. #efootball #pes20...</td>\n",
       "      <td>1394</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-10T07:08:44Z</td>\n",
       "      <td>vdF7WLM7q4w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abercrombie fall sweater vest 😍 #abercrombie</td>\n",
       "      <td>609</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-13T17:18:36Z</td>\n",
       "      <td>-kQoE1P4fnE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>EFFORTLESSLY CHIC SEZANE SPRING LOOKBOOK | THE...</td>\n",
       "      <td>3796</td>\n",
       "      <td>108</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-03-09T16:14:05Z</td>\n",
       "      <td>7mJtpkLB58A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>Abercrombie &amp; Fitch Rebranded… and it’s amazin...</td>\n",
       "      <td>1225</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-08-22T05:05:38Z</td>\n",
       "      <td>bneNL__G2Lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>ABERCROMBIE: WINTER, SPRING &amp; SUMMER HAUL | SALE!</td>\n",
       "      <td>1702</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-12-28T09:00:08Z</td>\n",
       "      <td>7h0Vu9gz64k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>Perfectly Loose &amp; Flattering Abercrombie Jeans...</td>\n",
       "      <td>4955</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-11-02T15:00:46Z</td>\n",
       "      <td>wFMCQFSPffQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>Legend Says She’s Still Twirling 💃🏻 #petiteout...</td>\n",
       "      <td>4479</td>\n",
       "      <td>156</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-28T01:47:09Z</td>\n",
       "      <td>oZNTlCK6_Vg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  Views  Likes  \\\n",
       "0     SUMMER TRY-ON HAUL | ABERCROMBIE, MASSIMO DUTT...  27156    647   \n",
       "1     Casual Winter Outfits ❄ | Amazon Corset | Get ...   7579    240   \n",
       "2     Abercrombie Haul. Shop on description😉 #abercr...   6139     58   \n",
       "3     Best effort to save a goal.. #efootball #pes20...   1394     30   \n",
       "4          Abercrombie fall sweater vest 😍 #abercrombie    609      6   \n",
       "...                                                 ...    ...    ...   \n",
       "2673  EFFORTLESSLY CHIC SEZANE SPRING LOOKBOOK | THE...   3796    108   \n",
       "2674  Abercrombie & Fitch Rebranded… and it’s amazin...   1225     28   \n",
       "2675  ABERCROMBIE: WINTER, SPRING & SUMMER HAUL | SALE!   1702     53   \n",
       "2676  Perfectly Loose & Flattering Abercrombie Jeans...   4955     52   \n",
       "2677  Legend Says She’s Still Twirling 💃🏻 #petiteout...   4479    156   \n",
       "\n",
       "      Comments        Published Date     Video ID  \n",
       "0           29  2024-06-07T16:49:41Z  mJtVWvBLltg  \n",
       "1            4  2023-01-31T16:52:14Z  4DfMiBEZm6Q  \n",
       "2            0  2022-08-31T14:55:56Z  f9ZbRX1ZeGk  \n",
       "3            0  2023-04-10T07:08:44Z  vdF7WLM7q4w  \n",
       "4            2  2024-09-13T17:18:36Z  -kQoE1P4fnE  \n",
       "...        ...                   ...          ...  \n",
       "2673        18  2023-03-09T16:14:05Z  7mJtpkLB58A  \n",
       "2674         3  2023-08-22T05:05:38Z  bneNL__G2Lo  \n",
       "2675         8  2024-12-28T09:00:08Z  7h0Vu9gz64k  \n",
       "2676         3  2023-11-02T15:00:46Z  wFMCQFSPffQ  \n",
       "2677         2  2024-03-28T01:47:09Z  oZNTlCK6_Vg  \n",
       "\n",
       "[2678 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Published Date' to datetime and keep only the date\n",
    "df[\"Published Date\"] = pd.to_datetime(df[\"Published Date\"]).dt.date\n",
    "\n",
    "# Aggregate YouTube data by date (sum Views, Likes, and Comments for the same date)\n",
    "youtube_summary = df.groupby(\"Published Date\").agg({\n",
    "    \"Views\": \"sum\",\n",
    "    \"Likes\": \"sum\",\n",
    "    \"Comments\": \"sum\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Video ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUMMER TRY-ON HAUL | ABERCROMBIE, MASSIMO DUTT...</td>\n",
       "      <td>27156</td>\n",
       "      <td>647</td>\n",
       "      <td>29</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>mJtVWvBLltg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casual Winter Outfits ❄ | Amazon Corset | Get ...</td>\n",
       "      <td>7579</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>4DfMiBEZm6Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abercrombie Haul. Shop on description😉 #abercr...</td>\n",
       "      <td>6139</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>f9ZbRX1ZeGk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best effort to save a goal.. #efootball #pes20...</td>\n",
       "      <td>1394</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>vdF7WLM7q4w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abercrombie fall sweater vest 😍 #abercrombie</td>\n",
       "      <td>609</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-13</td>\n",
       "      <td>-kQoE1P4fnE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>EFFORTLESSLY CHIC SEZANE SPRING LOOKBOOK | THE...</td>\n",
       "      <td>3796</td>\n",
       "      <td>108</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>7mJtpkLB58A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>Abercrombie &amp; Fitch Rebranded… and it’s amazin...</td>\n",
       "      <td>1225</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>bneNL__G2Lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>ABERCROMBIE: WINTER, SPRING &amp; SUMMER HAUL | SALE!</td>\n",
       "      <td>1702</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>7h0Vu9gz64k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>Perfectly Loose &amp; Flattering Abercrombie Jeans...</td>\n",
       "      <td>4955</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>wFMCQFSPffQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>Legend Says She’s Still Twirling 💃🏻 #petiteout...</td>\n",
       "      <td>4479</td>\n",
       "      <td>156</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>oZNTlCK6_Vg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  Views  Likes  \\\n",
       "0     SUMMER TRY-ON HAUL | ABERCROMBIE, MASSIMO DUTT...  27156    647   \n",
       "1     Casual Winter Outfits ❄ | Amazon Corset | Get ...   7579    240   \n",
       "2     Abercrombie Haul. Shop on description😉 #abercr...   6139     58   \n",
       "3     Best effort to save a goal.. #efootball #pes20...   1394     30   \n",
       "4          Abercrombie fall sweater vest 😍 #abercrombie    609      6   \n",
       "...                                                 ...    ...    ...   \n",
       "2673  EFFORTLESSLY CHIC SEZANE SPRING LOOKBOOK | THE...   3796    108   \n",
       "2674  Abercrombie & Fitch Rebranded… and it’s amazin...   1225     28   \n",
       "2675  ABERCROMBIE: WINTER, SPRING & SUMMER HAUL | SALE!   1702     53   \n",
       "2676  Perfectly Loose & Flattering Abercrombie Jeans...   4955     52   \n",
       "2677  Legend Says She’s Still Twirling 💃🏻 #petiteout...   4479    156   \n",
       "\n",
       "      Comments Published Date     Video ID  \n",
       "0           29     2024-06-07  mJtVWvBLltg  \n",
       "1            4     2023-01-31  4DfMiBEZm6Q  \n",
       "2            0     2022-08-31  f9ZbRX1ZeGk  \n",
       "3            0     2023-04-10  vdF7WLM7q4w  \n",
       "4            2     2024-09-13  -kQoE1P4fnE  \n",
       "...        ...            ...          ...  \n",
       "2673        18     2023-03-09  7mJtpkLB58A  \n",
       "2674         3     2023-08-22  bneNL__G2Lo  \n",
       "2675         8     2024-12-28  7h0Vu9gz64k  \n",
       "2676         3     2023-11-02  wFMCQFSPffQ  \n",
       "2677         2     2024-03-28  oZNTlCK6_Vg  \n",
       "\n",
       "[2678 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title             object\n",
       "Views              int64\n",
       "Likes              int64\n",
       "Comments           int64\n",
       "Published Date    object\n",
       "Video ID          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Video ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Published Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>winter clothing tryon haul (Urban Outfitters, ...</td>\n",
       "      <td>502</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>LU1eoN5XwdI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>HUGE Abercrombie Haul - Winter to Spring outfi...</td>\n",
       "      <td>13148</td>\n",
       "      <td>391</td>\n",
       "      <td>33</td>\n",
       "      <td>oVYsjmCiEog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>My ABERCROMBIE &amp; FITCH Haul &amp; Try-On</td>\n",
       "      <td>29590</td>\n",
       "      <td>1194</td>\n",
       "      <td>291</td>\n",
       "      <td>_ShQb6aRhXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>Shopping Haul!!! (PINK, Abercrombie Kids, ULTA...</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>lG1LGKVnTX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-10</th>\n",
       "      <td>SHOPPING HAUL!!!! PINK, ABERCROMBIE, ROSS (GRE...</td>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>fNZI5qaJNNQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>How to pronounce Abercrombie &amp; Fitch</td>\n",
       "      <td>13358</td>\n",
       "      <td>383</td>\n",
       "      <td>4</td>\n",
       "      <td>JEv-30287r4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>Abercrombie Loose Jean Review #abercrombie</td>\n",
       "      <td>1744</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>lcrg7q8dY7k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>@NotEnoughNelsons @nenfam #paisleenelson #dupe...</td>\n",
       "      <td>4587</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>r7zHJD5QQy0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>Vlog: New Hairstyle, Come Shopping With Me (Za...</td>\n",
       "      <td>15035</td>\n",
       "      <td>531</td>\n",
       "      <td>63</td>\n",
       "      <td>7svPcfRUHdU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>Famous Flags You're Guaranteed to Get Wrong!</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5KuFZ181rvQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2678 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Title  Views  \\\n",
       "Published Date                                                             \n",
       "2020-01-08      winter clothing tryon haul (Urban Outfitters, ...    502   \n",
       "2020-01-09      HUGE Abercrombie Haul - Winter to Spring outfi...  13148   \n",
       "2020-02-02                   My ABERCROMBIE & FITCH Haul & Try-On  29590   \n",
       "2020-02-03      Shopping Haul!!! (PINK, Abercrombie Kids, ULTA...    105   \n",
       "2020-02-10      SHOPPING HAUL!!!! PINK, ABERCROMBIE, ROSS (GRE...    157   \n",
       "...                                                           ...    ...   \n",
       "2024-12-30                   How to pronounce Abercrombie & Fitch  13358   \n",
       "2024-12-31             Abercrombie Loose Jean Review #abercrombie   1744   \n",
       "2024-12-31      @NotEnoughNelsons @nenfam #paisleenelson #dupe...   4587   \n",
       "2024-12-31      Vlog: New Hairstyle, Come Shopping With Me (Za...  15035   \n",
       "2024-12-31           Famous Flags You're Guaranteed to Get Wrong!      4   \n",
       "\n",
       "                Likes  Comments     Video ID  \n",
       "Published Date                                \n",
       "2020-01-08         13         0  LU1eoN5XwdI  \n",
       "2020-01-09        391        33  oVYsjmCiEog  \n",
       "2020-02-02       1194       291  _ShQb6aRhXA  \n",
       "2020-02-03          5         1  lG1LGKVnTX4  \n",
       "2020-02-10          5         3  fNZI5qaJNNQ  \n",
       "...               ...       ...          ...  \n",
       "2024-12-30        383         4  JEv-30287r4  \n",
       "2024-12-31         45         1  lcrg7q8dY7k  \n",
       "2024-12-31         85         1  r7zHJD5QQy0  \n",
       "2024-12-31        531        63  7svPcfRUHdU  \n",
       "2024-12-31          0         0  5KuFZ181rvQ  \n",
       "\n",
       "[2678 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2678 entries, 0 to 2677\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Title           2678 non-null   object        \n",
      " 1   Views           2678 non-null   int64         \n",
      " 2   Likes           2678 non-null   int64         \n",
      " 3   Comments        2678 non-null   int64         \n",
      " 4   Published Date  2678 non-null   datetime64[ns]\n",
      " 5   Video ID        2678 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(3), object(2)\n",
      "memory usage: 125.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df[\"Published Date\"] = pd.to_datetime(df[\"Published Date\"], errors=\"coerce\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Video ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUMMER TRY-ON HAUL | ABERCROMBIE, MASSIMO DUTT...</td>\n",
       "      <td>27156</td>\n",
       "      <td>647</td>\n",
       "      <td>29</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>mJtVWvBLltg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casual Winter Outfits ❄ | Amazon Corset | Get ...</td>\n",
       "      <td>7579</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>4DfMiBEZm6Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abercrombie Haul. Shop on description😉 #abercr...</td>\n",
       "      <td>6139</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>f9ZbRX1ZeGk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best effort to save a goal.. #efootball #pes20...</td>\n",
       "      <td>1394</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>vdF7WLM7q4w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abercrombie fall sweater vest 😍 #abercrombie</td>\n",
       "      <td>609</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-13</td>\n",
       "      <td>-kQoE1P4fnE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>EFFORTLESSLY CHIC SEZANE SPRING LOOKBOOK | THE...</td>\n",
       "      <td>3796</td>\n",
       "      <td>108</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>7mJtpkLB58A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>Abercrombie &amp; Fitch Rebranded… and it’s amazin...</td>\n",
       "      <td>1225</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>bneNL__G2Lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>ABERCROMBIE: WINTER, SPRING &amp; SUMMER HAUL | SALE!</td>\n",
       "      <td>1702</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>7h0Vu9gz64k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>Perfectly Loose &amp; Flattering Abercrombie Jeans...</td>\n",
       "      <td>4955</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>wFMCQFSPffQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>Legend Says She’s Still Twirling 💃🏻 #petiteout...</td>\n",
       "      <td>4479</td>\n",
       "      <td>156</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>oZNTlCK6_Vg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  Views  Likes  \\\n",
       "0     SUMMER TRY-ON HAUL | ABERCROMBIE, MASSIMO DUTT...  27156    647   \n",
       "1     Casual Winter Outfits ❄ | Amazon Corset | Get ...   7579    240   \n",
       "2     Abercrombie Haul. Shop on description😉 #abercr...   6139     58   \n",
       "3     Best effort to save a goal.. #efootball #pes20...   1394     30   \n",
       "4          Abercrombie fall sweater vest 😍 #abercrombie    609      6   \n",
       "...                                                 ...    ...    ...   \n",
       "2673  EFFORTLESSLY CHIC SEZANE SPRING LOOKBOOK | THE...   3796    108   \n",
       "2674  Abercrombie & Fitch Rebranded… and it’s amazin...   1225     28   \n",
       "2675  ABERCROMBIE: WINTER, SPRING & SUMMER HAUL | SALE!   1702     53   \n",
       "2676  Perfectly Loose & Flattering Abercrombie Jeans...   4955     52   \n",
       "2677  Legend Says She’s Still Twirling 💃🏻 #petiteout...   4479    156   \n",
       "\n",
       "      Comments Published Date     Video ID  \n",
       "0           29     2024-06-07  mJtVWvBLltg  \n",
       "1            4     2023-01-31  4DfMiBEZm6Q  \n",
       "2            0     2022-08-31  f9ZbRX1ZeGk  \n",
       "3            0     2023-04-10  vdF7WLM7q4w  \n",
       "4            2     2024-09-13  -kQoE1P4fnE  \n",
       "...        ...            ...          ...  \n",
       "2673        18     2023-03-09  7mJtpkLB58A  \n",
       "2674         3     2023-08-22  bneNL__G2Lo  \n",
       "2675         8     2024-12-28  7h0Vu9gz64k  \n",
       "2676         3     2023-11-02  wFMCQFSPffQ  \n",
       "2677         2     2024-03-28  oZNTlCK6_Vg  \n",
       "\n",
       "[2678 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Published Date\"] = pd.to_datetime(df[\"Published Date\"]).dt.date\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Views', 'Likes', 'Comments', 'Video ID'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Published Date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24768\\2939452951.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 2. Set \"Published Date\" as the DataFrame index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Published Date\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 3. Sort by the new datetime index (optional but recommended)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6118\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mNone of \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m are in the columns\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Published Date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# 2. Set \"Published Date\" as the DataFrame index\n",
    "df.set_index(\"Published Date\", inplace=True)\n",
    "\n",
    "# 3. Sort by the new datetime index (optional but recommended)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Check the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([2020-01-08, 2020-01-09, 2020-02-02, 2020-02-03, 2020-02-10, 2020-02-25,\n",
      "       2020-03-10, 2020-03-13, 2020-03-17, 2020-03-23,\n",
      "       ...\n",
      "       2024-12-28, 2024-12-28, 2024-12-29, 2024-12-29, 2024-12-30, 2024-12-30,\n",
      "       2024-12-31, 2024-12-31, 2024-12-31, 2024-12-31],\n",
      "      dtype='object', name='Published Date', length=2678)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2678 entries, 2020-01-08 to 2024-12-31\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Title     2678 non-null   object\n",
      " 1   Views     2678 non-null   int64 \n",
      " 2   Likes     2678 non-null   int64 \n",
      " 3   Comments  2678 non-null   int64 \n",
      " 4   Video ID  2678 non-null   object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 125.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.index)\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-01-08', '2020-01-09', '2020-02-02', '2020-02-03',\n",
      "               '2020-02-10', '2020-02-25', '2020-03-10', '2020-03-13',\n",
      "               '2020-03-17', '2020-03-23',\n",
      "               ...\n",
      "               '2024-12-28', '2024-12-28', '2024-12-29', '2024-12-29',\n",
      "               '2024-12-30', '2024-12-30', '2024-12-31', '2024-12-31',\n",
      "               '2024-12-31', '2024-12-31'],\n",
      "              dtype='datetime64[ns]', name='Published Date', length=2678, freq=None)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2678 entries, 2020-01-08 to 2024-12-31\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Title     2678 non-null   object\n",
      " 1   Views     2678 non-null   int64 \n",
      " 2   Likes     2678 non-null   int64 \n",
      " 3   Comments  2678 non-null   int64 \n",
      " 4   Video ID  2678 non-null   object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 125.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert the current index to datetime\n",
    "df.index = pd.to_datetime(df.index, errors=\"coerce\")\n",
    "\n",
    "# Now it should be a DatetimeIndex\n",
    "print(df.index)\n",
    "print(df.info())  # verify the new dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Quarter                                              Title     Views  \\\n",
      "0 2020-03-31  winter clothing tryon haul (Urban Outfitters, ...    178520   \n",
      "1 2020-06-30  📖 Genialne Fantasy! -  Joe Abercrombie Trylogi...  15366278   \n",
      "2 2020-09-30  BEST PETITE DENIM JEANS TRY-ON & REVIEW / Levi...    338531   \n",
      "3 2020-12-31  A&F 90's Straight Ultra High Rise Jean Review ...  15216055   \n",
      "4 2021-03-31  Abercrombie and Fitch + Hollister TRY-ON HAUL ...   8583548   \n",
      "\n",
      "    Likes  Comments                                           Video ID  \\\n",
      "0    4416       724  LU1eoN5XwdIoVYsjmCiEog_ShQb6aRhXAlG1LGKVnTX4fN...   \n",
      "1  149656     40572  THBt_02JOnwZ12X9qnrL_cCiiHSOpnWPwEHzaTl1YCMYcr...   \n",
      "2   10457      1621  dXmU5ektbvY2biRVTfd_zMWMT999Y7cuIQvsrMyPOkz0PA...   \n",
      "3   82214      1728  s0MJjGNV1g04ixaHHMuMF8KhlE66AMnEQKrvT29XS-Zk92...   \n",
      "4   92132      7037  kqNd9SinWBQwDhhzpnVYmkU9NFa1zcABcl2pZntqkubI3H...   \n",
      "\n",
      "   Video_Count  \n",
      "0           11  \n",
      "1           25  \n",
      "2           39  \n",
      "3           49  \n",
      "4           57  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24768\\267820408.py:2: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
      "  df_quarterly = df.resample(\"Q\").sum()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24768\\267820408.py:3: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
      "  df_quarterly[\"Video_Count\"] = df.resample(\"Q\")[\"Title\"].count()\n"
     ]
    }
   ],
   "source": [
    "# Example: Quarterly aggregation\n",
    "df_quarterly = df.resample(\"Q\").sum()\n",
    "df_quarterly[\"Video_Count\"] = df.resample(\"Q\")[\"Title\"].count()\n",
    "\n",
    "df_quarterly.reset_index(inplace=True)\n",
    "df_quarterly.rename(columns={\"Published Date\": \"Quarter\"}, inplace=True)\n",
    "\n",
    "print(df_quarterly.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quarterly.to_csv(\"my_youtube_data.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Title</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Video_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>winter clothing tryon haul (Urban Outfitters, ...</td>\n",
       "      <td>178520</td>\n",
       "      <td>4416</td>\n",
       "      <td>724</td>\n",
       "      <td>LU1eoN5XwdIoVYsjmCiEog_ShQb6aRhXAlG1LGKVnTX4fN...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>📖 Genialne Fantasy! -  Joe Abercrombie Trylogi...</td>\n",
       "      <td>15366278</td>\n",
       "      <td>149656</td>\n",
       "      <td>40572</td>\n",
       "      <td>THBt_02JOnwZ12X9qnrL_cCiiHSOpnWPwEHzaTl1YCMYcr...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>BEST PETITE DENIM JEANS TRY-ON &amp; REVIEW / Levi...</td>\n",
       "      <td>338531</td>\n",
       "      <td>10457</td>\n",
       "      <td>1621</td>\n",
       "      <td>dXmU5ektbvY2biRVTfd_zMWMT999Y7cuIQvsrMyPOkz0PA...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>A&amp;F 90's Straight Ultra High Rise Jean Review ...</td>\n",
       "      <td>15216055</td>\n",
       "      <td>82214</td>\n",
       "      <td>1728</td>\n",
       "      <td>s0MJjGNV1g04ixaHHMuMF8KhlE66AMnEQKrvT29XS-Zk92...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>Abercrombie and Fitch + Hollister TRY-ON HAUL ...</td>\n",
       "      <td>8583548</td>\n",
       "      <td>92132</td>\n",
       "      <td>7037</td>\n",
       "      <td>kqNd9SinWBQwDhhzpnVYmkU9NFa1zcABcl2pZntqkubI3H...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>Cómo leer a Joe Abercrombie | Guía de lectura1...</td>\n",
       "      <td>13742932</td>\n",
       "      <td>256043</td>\n",
       "      <td>9564</td>\n",
       "      <td>95JJrEaDbOkMw7_utD6MS0QJhidVh-xAgL3beyBJqRCI2M...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>TESTING OUT THE POPULAR ABERCROMBIE JEANS (US ...</td>\n",
       "      <td>8738494</td>\n",
       "      <td>164152</td>\n",
       "      <td>4101</td>\n",
       "      <td>770HfbGIFdUECqQucbp14EBl16o6vB4V8JCDSDjVjzY4GN...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>MANGO try On Fall HAUL 2021 ABERCROMBIE Shoppi...</td>\n",
       "      <td>1758087</td>\n",
       "      <td>40825</td>\n",
       "      <td>3151</td>\n",
       "      <td>_GF7yeVzuvQAyA68Y8mHPsltyBoY2zwMoNWhua1nWF5wAt...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>Abercrombie Winter HaulBest High Rise Jeans fo...</td>\n",
       "      <td>3487678</td>\n",
       "      <td>79034</td>\n",
       "      <td>5690</td>\n",
       "      <td>Kh_ShDO9MXUXk3XBgEGodI60Q5o9T0c2cAEZ9vIN7UIUyz...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>2022 Abercrombie &amp; Fitch Spring Try On Haul | ...</td>\n",
       "      <td>3218844</td>\n",
       "      <td>120073</td>\n",
       "      <td>4582</td>\n",
       "      <td>qMCPAUZGoC8CMxKW_NKjNsJzXlJSadJ34fYItvLpyrk0TX...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>ABERCROMBIE &amp; FITCH First Instinct VS First In...</td>\n",
       "      <td>13232523</td>\n",
       "      <td>63248</td>\n",
       "      <td>1726</td>\n",
       "      <td>65Ir-SzcDEkwWH4MYAZl6EjTYErvG0s38mrbV4SyVoZ4MW...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Abercrombie outfits you just ✨ need ✨ this fal...</td>\n",
       "      <td>17946875</td>\n",
       "      <td>492111</td>\n",
       "      <td>12026</td>\n",
       "      <td>caS9ReBiB0sPUe2zYPhZjs1m5RQy7K1wwh1Xrcnuy43gm2...</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>Abercrombie &amp; Fitch Trousers Try-on Haul | pet...</td>\n",
       "      <td>10431041</td>\n",
       "      <td>302718</td>\n",
       "      <td>8500</td>\n",
       "      <td>MJh6BT2nlMYtQXPO5Qv66sTk4V87HOEoYvE7iGhgZmHA2c...</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>Abercrombie Try On (Part 1 of 2) #abercrombie ...</td>\n",
       "      <td>42828055</td>\n",
       "      <td>954680</td>\n",
       "      <td>22681</td>\n",
       "      <td>C_GyoxBe63ct44R6xFEuAIPsh544r44Ls0eZkIFFlhgMap...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>How To Build An Old Money Aesthetic Wardrobe (...</td>\n",
       "      <td>13450351</td>\n",
       "      <td>223420</td>\n",
       "      <td>6523</td>\n",
       "      <td>eiLFqHYBLAIoh5Surdx1nocyBralfu0UAJ_su14CcIWonN...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Top Chef's Knives for 2023 #shotsI Found 5 Of ...</td>\n",
       "      <td>12603259</td>\n",
       "      <td>315317</td>\n",
       "      <td>9026</td>\n",
       "      <td>MiR-TQ92vu4urI9dgtNw38Sw-8YVYyU1sihlqt7I58dQ8d...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>toronto haul #haul #clothes #beauty #lululemon...</td>\n",
       "      <td>5101915</td>\n",
       "      <td>221791</td>\n",
       "      <td>3711</td>\n",
       "      <td>wGe-G55tExc0Runhr4yBUk7Xpa3QG4OxUWawbcfC7QPc9Q...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>Abercrombie Activewear on 3 Different Body Typ...</td>\n",
       "      <td>21130578</td>\n",
       "      <td>431219</td>\n",
       "      <td>5440</td>\n",
       "      <td>ILO7sck13Dgwa98GSvVETgUqxDTI6biDc2VZOluV7uo8dU...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>A summer outfit today featuring this Abercromb...</td>\n",
       "      <td>14589148</td>\n",
       "      <td>357620</td>\n",
       "      <td>18565</td>\n",
       "      <td>T34nk47rbcwtr9oBAsy11E7k0DSx1W6E8pMywUPwR7Mo5l...</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>this weeks fits!!  🤍🎀🎱🪩#ootd#fits#fashion#shop...</td>\n",
       "      <td>16980101</td>\n",
       "      <td>480818</td>\n",
       "      <td>20165</td>\n",
       "      <td>7e6Cn67XksIC6Pu2hOj4D04J5YC4bc_BIs9ZM11oa2aUwY...</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Quarter                                              Title     Views  \\\n",
       "0  2020-03-31  winter clothing tryon haul (Urban Outfitters, ...    178520   \n",
       "1  2020-06-30  📖 Genialne Fantasy! -  Joe Abercrombie Trylogi...  15366278   \n",
       "2  2020-09-30  BEST PETITE DENIM JEANS TRY-ON & REVIEW / Levi...    338531   \n",
       "3  2020-12-31  A&F 90's Straight Ultra High Rise Jean Review ...  15216055   \n",
       "4  2021-03-31  Abercrombie and Fitch + Hollister TRY-ON HAUL ...   8583548   \n",
       "5  2021-06-30  Cómo leer a Joe Abercrombie | Guía de lectura1...  13742932   \n",
       "6  2021-09-30  TESTING OUT THE POPULAR ABERCROMBIE JEANS (US ...   8738494   \n",
       "7  2021-12-31  MANGO try On Fall HAUL 2021 ABERCROMBIE Shoppi...   1758087   \n",
       "8  2022-03-31  Abercrombie Winter HaulBest High Rise Jeans fo...   3487678   \n",
       "9  2022-06-30  2022 Abercrombie & Fitch Spring Try On Haul | ...   3218844   \n",
       "10 2022-09-30  ABERCROMBIE & FITCH First Instinct VS First In...  13232523   \n",
       "11 2022-12-31  Abercrombie outfits you just ✨ need ✨ this fal...  17946875   \n",
       "12 2023-03-31  Abercrombie & Fitch Trousers Try-on Haul | pet...  10431041   \n",
       "13 2023-06-30  Abercrombie Try On (Part 1 of 2) #abercrombie ...  42828055   \n",
       "14 2023-09-30  How To Build An Old Money Aesthetic Wardrobe (...  13450351   \n",
       "15 2023-12-31  Top Chef's Knives for 2023 #shotsI Found 5 Of ...  12603259   \n",
       "16 2024-03-31  toronto haul #haul #clothes #beauty #lululemon...   5101915   \n",
       "17 2024-06-30  Abercrombie Activewear on 3 Different Body Typ...  21130578   \n",
       "18 2024-09-30  A summer outfit today featuring this Abercromb...  14589148   \n",
       "19 2024-12-31  this weeks fits!!  🤍🎀🎱🪩#ootd#fits#fashion#shop...  16980101   \n",
       "\n",
       "     Likes  Comments                                           Video ID  \\\n",
       "0     4416       724  LU1eoN5XwdIoVYsjmCiEog_ShQb6aRhXAlG1LGKVnTX4fN...   \n",
       "1   149656     40572  THBt_02JOnwZ12X9qnrL_cCiiHSOpnWPwEHzaTl1YCMYcr...   \n",
       "2    10457      1621  dXmU5ektbvY2biRVTfd_zMWMT999Y7cuIQvsrMyPOkz0PA...   \n",
       "3    82214      1728  s0MJjGNV1g04ixaHHMuMF8KhlE66AMnEQKrvT29XS-Zk92...   \n",
       "4    92132      7037  kqNd9SinWBQwDhhzpnVYmkU9NFa1zcABcl2pZntqkubI3H...   \n",
       "5   256043      9564  95JJrEaDbOkMw7_utD6MS0QJhidVh-xAgL3beyBJqRCI2M...   \n",
       "6   164152      4101  770HfbGIFdUECqQucbp14EBl16o6vB4V8JCDSDjVjzY4GN...   \n",
       "7    40825      3151  _GF7yeVzuvQAyA68Y8mHPsltyBoY2zwMoNWhua1nWF5wAt...   \n",
       "8    79034      5690  Kh_ShDO9MXUXk3XBgEGodI60Q5o9T0c2cAEZ9vIN7UIUyz...   \n",
       "9   120073      4582  qMCPAUZGoC8CMxKW_NKjNsJzXlJSadJ34fYItvLpyrk0TX...   \n",
       "10   63248      1726  65Ir-SzcDEkwWH4MYAZl6EjTYErvG0s38mrbV4SyVoZ4MW...   \n",
       "11  492111     12026  caS9ReBiB0sPUe2zYPhZjs1m5RQy7K1wwh1Xrcnuy43gm2...   \n",
       "12  302718      8500  MJh6BT2nlMYtQXPO5Qv66sTk4V87HOEoYvE7iGhgZmHA2c...   \n",
       "13  954680     22681  C_GyoxBe63ct44R6xFEuAIPsh544r44Ls0eZkIFFlhgMap...   \n",
       "14  223420      6523  eiLFqHYBLAIoh5Surdx1nocyBralfu0UAJ_su14CcIWonN...   \n",
       "15  315317      9026  MiR-TQ92vu4urI9dgtNw38Sw-8YVYyU1sihlqt7I58dQ8d...   \n",
       "16  221791      3711  wGe-G55tExc0Runhr4yBUk7Xpa3QG4OxUWawbcfC7QPc9Q...   \n",
       "17  431219      5440  ILO7sck13Dgwa98GSvVETgUqxDTI6biDc2VZOluV7uo8dU...   \n",
       "18  357620     18565  T34nk47rbcwtr9oBAsy11E7k0DSx1W6E8pMywUPwR7Mo5l...   \n",
       "19  480818     20165  7e6Cn67XksIC6Pu2hOj4D04J5YC4bc_BIs9ZM11oa2aUwY...   \n",
       "\n",
       "    Video_Count  \n",
       "0            11  \n",
       "1            25  \n",
       "2            39  \n",
       "3            49  \n",
       "4            57  \n",
       "5            49  \n",
       "6            68  \n",
       "7            99  \n",
       "8           126  \n",
       "9           117  \n",
       "10          126  \n",
       "11          263  \n",
       "12          271  \n",
       "13          188  \n",
       "14          181  \n",
       "15          168  \n",
       "16          156  \n",
       "17          150  \n",
       "18          254  \n",
       "19          281  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quarterly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
